
  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                                                                                          | 4/80 [00:01<00:35,  2.15it/s]
{'loss': 13.8967, 'learning_rate': 9.875000000000001e-06, 'epoch': 0.12}
{'loss': 15.6844, 'learning_rate': 9.75e-06, 'epoch': 0.25}
{'loss': 13.0668, 'learning_rate': 9.625e-06, 'epoch': 0.38}
{'loss': 16.3689, 'learning_rate': 9.5e-06, 'epoch': 0.5}
{'loss': 14.9309, 'learning_rate': 9.375000000000001e-06, 'epoch': 0.62}
{'loss': 13.3525, 'learning_rate': 9.250000000000001e-06, 'epoch': 0.75}
{'loss': 14.5143, 'learning_rate': 9.125e-06, 'epoch': 0.88}
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                                                                                | 8/80 [00:02<00:19,  3.66it/s]

{'eval_loss': 13.782395362854004, 'eval_top1_acc': 0.0, 'eval_rank_acc': 0.469314, 'eval_runtime': 2.7904, 'eval_samples_per_second': 99.27, 'eval_steps_per_second': 12.543, 'epoch': 1.0}
{'loss': 12.3631, 'learning_rate': 8.875e-06, 'epoch': 1.12}
{'loss': 12.6375, 'learning_rate': 8.750000000000001e-06, 'epoch': 1.25}
{'loss': 12.975, 'learning_rate': 8.625000000000001e-06, 'epoch': 1.38}
{'loss': 13.4754, 'learning_rate': 8.5e-06, 'epoch': 1.5}
{'loss': 11.932, 'learning_rate': 8.375e-06, 'epoch': 1.62}
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                                                            | 16/80 [00:06<00:17,  3.66it/s]
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                                     | 11/35 [00:00<00:01, 16.53it/s]
{'loss': 12.1882, 'learning_rate': 8.125000000000001e-06, 'epoch': 1.88}

{'eval_loss': 10.360577583312988, 'eval_top1_acc': 0.0, 'eval_rank_acc': 0.472924, 'eval_runtime': 2.6525, 'eval_samples_per_second': 104.43, 'eval_steps_per_second': 13.195, 'epoch': 2.0}
{'loss': 9.2728, 'learning_rate': 7.875e-06, 'epoch': 2.12}
{'loss': 7.9882, 'learning_rate': 7.75e-06, 'epoch': 2.25}
{'loss': 10.5769, 'learning_rate': 7.625e-06, 'epoch': 2.38}
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                                        | 24/80 [00:11<00:15,  3.58it/s]
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                                                 | 9/35 [00:00<00:01, 16.10it/s]
{'loss': 9.8211, 'learning_rate': 7.375000000000001e-06, 'epoch': 2.62}
{'loss': 10.3732, 'learning_rate': 7.25e-06, 'epoch': 2.75}
{'loss': 8.6975, 'learning_rate': 7.125e-06, 'epoch': 2.88}

{'eval_loss': 7.900201797485352, 'eval_top1_acc': 0.0, 'eval_rank_acc': 0.480144, 'eval_runtime': 2.642, 'eval_samples_per_second': 104.846, 'eval_steps_per_second': 13.248, 'epoch': 3.0}
{'loss': 8.3079, 'learning_rate': 6.875e-06, 'epoch': 3.12}
{'loss': 7.1411, 'learning_rate': 6.750000000000001e-06, 'epoch': 3.25}
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                     | 32/80 [00:15<00:13,  3.51it/s]
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                                                                        | 5/35 [00:00<00:01, 17.69it/s]
{'loss': 8.4647, 'learning_rate': 6.5000000000000004e-06, 'epoch': 3.5}
{'loss': 8.0582, 'learning_rate': 6.375e-06, 'epoch': 3.62}
{'loss': 7.3452, 'learning_rate': 6.25e-06, 'epoch': 3.75}
{'loss': 7.9793, 'learning_rate': 6.125000000000001e-06, 'epoch': 3.88}

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 31/35 [00:02<00:00, 12.58it/s]
{'eval_loss': 6.424686431884766, 'eval_top1_acc': 0.0, 'eval_rank_acc': 0.501805, 'eval_runtime': 2.6678, 'eval_samples_per_second': 103.83, 'eval_steps_per_second': 13.119, 'epoch': 4.0}

  0%|                                                                                                                                                                                                            | 0/35 [00:00<?, ?it/s]
{'loss': 7.8187, 'learning_rate': 5.75e-06, 'epoch': 4.25}
{'loss': 6.7152, 'learning_rate': 5.625e-06, 'epoch': 4.38}
{'loss': 5.768, 'learning_rate': 5.500000000000001e-06, 'epoch': 4.5}
{'loss': 5.9179, 'learning_rate': 5.375e-06, 'epoch': 4.62}
{'loss': 6.7925, 'learning_rate': 5.2500000000000006e-06, 'epoch': 4.75}
{'loss': 5.243, 'learning_rate': 5.125e-06, 'epoch': 4.88}


{'eval_loss': 5.346668243408203, 'eval_top1_acc': 0.0, 'eval_rank_acc': 0.545126, 'eval_runtime': 2.7692, 'eval_samples_per_second': 100.028, 'eval_steps_per_second': 12.639, 'epoch': 5.0}
{'loss': 7.9273, 'learning_rate': 4.875e-06, 'epoch': 5.12}
{'loss': 6.122, 'learning_rate': 4.75e-06, 'epoch': 5.25}
{'loss': 5.38, 'learning_rate': 4.625000000000001e-06, 'epoch': 5.38}
{'loss': 6.239, 'learning_rate': 4.5e-06, 'epoch': 5.5}
{'loss': 5.7965, 'learning_rate': 4.3750000000000005e-06, 'epoch': 5.62}
{'loss': 5.8289, 'learning_rate': 4.25e-06, 'epoch': 5.75}
{'loss': 5.4552, 'learning_rate': 4.125e-06, 'epoch': 5.88}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                              | 48/80 [00:24<00:09,  3.51it/s]

{'eval_loss': 4.365345478057861, 'eval_top1_acc': 0.0, 'eval_rank_acc': 0.523466, 'eval_runtime': 2.6848, 'eval_samples_per_second': 103.172, 'eval_steps_per_second': 13.036, 'epoch': 6.0}
{'loss': 5.3146, 'learning_rate': 3.875e-06, 'epoch': 6.12}
{'loss': 4.6642, 'learning_rate': 3.7500000000000005e-06, 'epoch': 6.25}
{'loss': 5.7678, 'learning_rate': 3.625e-06, 'epoch': 6.38}
{'loss': 4.7633, 'learning_rate': 3.5e-06, 'epoch': 6.5}
{'loss': 4.8567, 'learning_rate': 3.3750000000000003e-06, 'epoch': 6.62}
{'loss': 5.1121, 'learning_rate': 3.2500000000000002e-06, 'epoch': 6.75}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                          | 56/80 [00:28<00:06,  3.53it/s]
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                          | 13/35 [00:00<00:01, 14.45it/s]

{'eval_loss': 3.5211141109466553, 'eval_top1_acc': 0.00722, 'eval_rank_acc': 0.541516, 'eval_runtime': 2.6687, 'eval_samples_per_second': 103.794, 'eval_steps_per_second': 13.115, 'epoch': 7.0}
{'loss': 5.5407, 'learning_rate': 2.875e-06, 'epoch': 7.12}
{'loss': 4.8607, 'learning_rate': 2.7500000000000004e-06, 'epoch': 7.25}
{'loss': 4.9146, 'learning_rate': 2.6250000000000003e-06, 'epoch': 7.38}
{'loss': 4.6684, 'learning_rate': 2.5e-06, 'epoch': 7.5}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 64/80 [00:33<00:04,  3.65it/s]
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                                                 | 9/35 [00:00<00:01, 16.14it/s]
{'loss': 4.7726, 'learning_rate': 2.25e-06, 'epoch': 7.75}
{'loss': 4.3803, 'learning_rate': 2.125e-06, 'epoch': 7.88}

{'eval_loss': 2.944056510925293, 'eval_top1_acc': 0.01444, 'eval_rank_acc': 0.559567, 'eval_runtime': 2.6532, 'eval_samples_per_second': 104.401, 'eval_steps_per_second': 13.191, 'epoch': 8.0}
{'loss': 5.0438, 'learning_rate': 1.8750000000000003e-06, 'epoch': 8.12}
{'loss': 4.4803, 'learning_rate': 1.75e-06, 'epoch': 8.25}
{'loss': 4.7652, 'learning_rate': 1.6250000000000001e-06, 'epoch': 8.38}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 72/80 [00:37<00:02,  3.63it/s]
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                                                                        | 5/35 [00:00<00:01, 18.11it/s]
{'loss': 4.0719, 'learning_rate': 1.3750000000000002e-06, 'epoch': 8.62}
{'loss': 3.9186, 'learning_rate': 1.25e-06, 'epoch': 8.75}
{'loss': 4.4106, 'learning_rate': 1.125e-06, 'epoch': 8.88}

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 33/35 [00:02<00:00, 12.98it/s]
{'eval_loss': 2.615786075592041, 'eval_top1_acc': 0.032491, 'eval_rank_acc': 0.541516, 'eval_runtime': 2.6886, 'eval_samples_per_second': 103.028, 'eval_steps_per_second': 13.018, 'epoch': 9.0}
{'loss': 4.3068, 'learning_rate': 8.75e-07, 'epoch': 9.12}

{'loss': 4.544, 'learning_rate': 6.25e-07, 'epoch': 9.38}
{'loss': 3.4943, 'learning_rate': 5.000000000000001e-07, 'epoch': 9.5}
{'loss': 4.6464, 'learning_rate': 3.75e-07, 'epoch': 9.62}
{'loss': 4.521, 'learning_rate': 2.5000000000000004e-07, 'epoch': 9.75}
{'loss': 3.675, 'learning_rate': 1.2500000000000002e-07, 'epoch': 9.88}
{'loss': 4.0491, 'learning_rate': 0.0, 'epoch': 10.0}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                            | 27/35 [00:01<00:00, 12.85it/s]
{'eval_loss': 2.5075290203094482, 'eval_top1_acc': 0.050542, 'eval_rank_acc': 0.545126, 'eval_runtime': 2.7381, 'eval_samples_per_second': 101.166, 'eval_steps_per_second': 12.783, 'epoch': 10.0}
  File ".\src\encoder_decoder.py", line 468, in <module>
    main()
  File ".\src\encoder_decoder.py", line 449, in main
    for results in log_history
  File ".\src\encoder_decoder.py", line 449, in <listcomp>
    for results in log_history
TypeError: unsupported operand type(s) for |: 'dict' and 'dict'
[31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mTraceback (most recent call last)[31m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
[31mâ”‚[39m [33mF:\h2lab\pet\prompt_semantics\.\src\encoder_decoder.py[39m:[94m468[39m in [92m<module>[39m                           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   465 â”‚   [94mfor[39m seed [95min[39m tqdm(args.seeds, desc=[33m'Random Seeds'[39m, disable=[96mlen[39m(args.seeds) == [94m1[39m):       [31mâ”‚
[31mâ”‚[39m   466 â”‚   â”‚   hf.set_seed(seed)                                                                  [31mâ”‚
[31mâ”‚[39m   467 â”‚   â”‚   args.current_seed = seed                                                           [31mâ”‚
[31mâ”‚[39m [31mâ± [39m468 â”‚   â”‚   main()                                                                             [31mâ”‚
[31mâ”‚[39m   469                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mF:\h2lab\pet\prompt_semantics\.\src\encoder_decoder.py[39m:[94m449[39m in [92mmain[39m                               [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   446 â”‚   â”‚   â”‚   torch.cuda.empty_cache()                                                       [31mâ”‚
[31mâ”‚[39m   447 â”‚   â”‚   â”‚   result_table += [                                                              [31mâ”‚
[31mâ”‚[39m   448 â”‚   â”‚   â”‚   â”‚   setup_info | {k: v [94mfor[39m k, v [95min[39m results.items() [94mif[39m k [95min[39m table_columns}      [31mâ”‚
[31mâ”‚[39m [31mâ± [39m449 â”‚   â”‚   â”‚   â”‚   [94mfor[39m results [95min[39m log_history                                                 [31mâ”‚
[31mâ”‚[39m   450 â”‚   â”‚   â”‚   ]                                                                              [31mâ”‚
[31mâ”‚[39m   451 â”‚   â”‚   â”‚   # Include all unspecified columns                                              [31mâ”‚
[31mâ”‚[39m   452 â”‚   â”‚   â”‚   # result_table = [setup_info | result for result in log_history]               [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mF:\h2lab\pet\prompt_semantics\.\src\encoder_decoder.py[39m:[94m449[39m in [92m<listcomp>[39m                         [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   446 â”‚   â”‚   â”‚   torch.cuda.empty_cache()                                                       [31mâ”‚
[31mâ”‚[39m   447 â”‚   â”‚   â”‚   result_table += [                                                              [31mâ”‚
[31mâ”‚[39m   448 â”‚   â”‚   â”‚   â”‚   setup_info | {k: v [94mfor[39m k, v [95min[39m results.items() [94mif[39m k [95min[39m table_columns}      [31mâ”‚
[31mâ”‚[39m [31mâ± [39m449 â”‚   â”‚   â”‚   â”‚   [94mfor[39m results [95min[39m log_history                                                 [31mâ”‚
[31mâ”‚[39m   450 â”‚   â”‚   â”‚   ]                                                                              [31mâ”‚
[31mâ”‚[39m   451 â”‚   â”‚   â”‚   # Include all unspecified columns                                              [31mâ”‚
[31mâ”‚[39m   452 â”‚   â”‚   â”‚   # result_table = [setup_info | result for result in log_history]               [31mâ”‚
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[1mTypeError: [22munsupported operand [1mtype([22ms[1m)[22m for |: [32m'dict'[39m and [32m'dict'